{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer as StandardScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, GaussianNoise\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 10000/2\n",
    "p = np.random.uniform(0.3,10.,n_particles)\n",
    "mp = np.random.uniform(1/10.,1/0.3,n_particles)\n",
    "p_mp = 1./mp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(p_mp,50,range=(0.,10.))\n",
    "plt.show()\n",
    "p_ges = np.concatenate([p,p_mp])\n",
    "plt.hist(p_ges,50,range=(0,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_pi = 0.139\n",
    "mass_mu = 0.105\n",
    "mass_e = 0.000511\n",
    "mass_p = 0.938\n",
    "mass_K = 0.494\n",
    "masses = [mass_pi, mass_mu, mass_e, mass_p, mass_K]\n",
    "masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = []\n",
    "for mass in masses:\n",
    "    ITS_tmp = []\n",
    "    TPCROC0_tmp = []\n",
    "    TPCROC1_tmp = []\n",
    "    TPCROC2_tmp = []\n",
    "    TRD_tmp = []\n",
    "    TOF_tmp = []\n",
    "    for p in p_ges:\n",
    "        bg = p/mass\n",
    "        beta = bg/math.sqrt(1.+ bg*bg);\n",
    "        BBS = ROOT.AliExternalTrackParam.BetheBlochSolid(bg)\n",
    "        BBA = ROOT.AliExternalTrackParam.BetheBlochAleph(bg)\n",
    "        ITS_tmp.append(np.random.normal(BBS,0.1*BBS) ) ## ITS dEdx = smeared gaus 10% \n",
    "        TPCROC0_tmp.append(np.random.normal(BBA,0.1*BBA) )## TPC dEdx = smeared gaus 10% for 1st layer\n",
    "        TPCROC1_tmp.append(np.random.normal(BBA,0.1*BBA) )  ## TPC dEdx = smeared gaus 10% for 2nd layer\n",
    "        TPCROC2_tmp.append(np.random.normal(BBA,0.1*BBA) )  ## TPC dEdx = smeared gaus 10% for 3d layer\n",
    "        TRD_tmp.append(np.random.normal(BBA,0.1*BBA) )  ## TRD dEdx = smeared gaus 10% \n",
    "        TOF_tmp.append(np.random.normal(beta,0.1*beta) )  ## TOF - smeared with .... gaussian\n",
    "    signals.append({'ITS': ITS_tmp, 'TPCROC0': TPCROC0_tmp, 'TPCROC1': TPCROC1_tmp, 'TPCROC1': TPCROC1_tmp, \n",
    "                    'TPCROC2': TPCROC2_tmp, 'TRD': TRD_tmp, 'TOF': TOF_tmp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[]\n",
    "for i, val in enumerate(masses):\n",
    "    df = pd.DataFrame.from_dict(signals[i])\n",
    "    df['p'] = pd.Series(p_ges, index=df.index)\n",
    "    df['particle'] = pd.Series(i, index=df.index)\n",
    "    df_list.append(df)\n",
    "df_all = pd.concat([df_list[0],df_list[2],df_list[3],df_list[4]], ignore_index=True)\n",
    "plt.hist2d(df_all[\"p\"], df_all[\"TPCROC1\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(df_all)\n",
    "probability = 0.95\n",
    "\n",
    "flips_raw = (1*(np.random.random(size=6*N)<probability)).reshape(6,-1)\n",
    "\n",
    "flips=flips_raw[0]\n",
    "for i in range(1,6):\n",
    "    # (1<<i = 2**i)\n",
    "    flips=flips_raw[i]*(1<<i) + flips\n",
    "\n",
    "\n",
    "df_all.loc[:,'flips']=flips\n",
    "df_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare \"flips-Data\" and weights\n",
    "for i ,name in enumerate(['ITS','TOF','TPCROC0','TPCROC1','TPCROC2','TRD']):\n",
    "    # calculate \"flip= 0/1\"\n",
    "    f=(np.array(df_all['flips'])>>i)&1\n",
    "    # if f=0 substitute value by mean\n",
    "    m=df_all[name].mean()\n",
    "    df_all.loc[:,name+'_mr']= df_all[name].multiply(f,axis='index')+m*(1-f) #mean replaced\n",
    "    df_all.loc[:,name+'_w']=1.0*f #weight\n",
    "    df_all.loc[:,name+'_0']= df_all[name].multiply(f,axis='index') #zeros\n",
    "    \n",
    "# generate data for stage 2\n",
    "df_stage_2=df_all.copy()\n",
    "df_stage_3=df_all.copy()\n",
    "df_all[df_all['particle']==0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test =train_test_split(df_all, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred,weights):\n",
    "    return K.mean(K.square((y_true - y_pred)*weights))\n",
    "\n",
    "inputs = Input(shape=(6,))\n",
    "inputw = Input(shape=(6,))\n",
    "noise = GaussianNoise(0.2)(inputs)\n",
    "enc1   = Dense(units=64, activation='selu')(noise)\n",
    "enc2   = Dense(units=64, activation='selu')(enc1)\n",
    "enc3   = Dense(units=64, activation='selu')(enc2)\n",
    "enc4   = Dense(units=64, activation='selu')(enc3)\n",
    "layer0 = Dense(units=2 , activation='selu')(enc4)\n",
    "dec1   = Dense(units=64, activation='selu')(layer0)\n",
    "dec2   = Dense(units=64, activation='selu')(dec1)\n",
    "dec3   = Dense(units=64, activation='selu')(dec2)\n",
    "dec4   = Dense(units=64, activation='selu')(dec3)\n",
    "outputs= Dense(units=6, activation='linear')(dec4)\n",
    "\n",
    "c_loss = partial(custom_loss, weights=inputw)\n",
    "        \n",
    "modelpt = Model(inputs=inputs,outputs=outputs)\n",
    "models2 = Model(inputs=inputs,outputs=outputs)\n",
    "modell = Model(inputs=inputs,outputs=outputs)\n",
    "model0 = Model(inputs=inputs,outputs=outputs)\n",
    "model1 = Model(inputs=[inputs,inputw],outputs=outputs)\n",
    "modelpt.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mse'])\n",
    "models2.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mse'])\n",
    "modell.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mse'])\n",
    "model0.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mse'])\n",
    "model1.compile(loss=c_loss,\n",
    "              optimizer='adam',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perfect tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pt = train[[\"ITS\", \"TOF\", \"TPCROC0\", \"TPCROC1\", \"TPCROC2\", \"TRD\"]]\n",
    "test_pt = test[[\"ITS\", \"TOF\", \"TPCROC0\", \"TPCROC1\", \"TPCROC2\", \"TRD\"]]\n",
    "scaler_pt = StandardScaler()\n",
    "scaler_pt.fit( train[[\"ITS\", \"TOF\", \"TPCROC0\", \"TPCROC1\", \"TPCROC2\", \"TRD\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpt.fit(scaler_pt.transform(train_pt), scaler_pt.transform(train_pt), epochs=5, batch_size=32, \n",
    "          validation_data=[scaler_pt.transform(test_pt),scaler_pt.transform(test_pt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = scaler_pt.inverse_transform(modelpt.predict(scaler_pt.transform(test_pt)))\n",
    "AE_predict = pd.DataFrame(out)\n",
    "AE_predict.columns = [\"ITS_ae\", \"TOF_ae\", \"TPCROC0_ae\", \"TPCROC1_ae\", \"TPCROC2_ae\", \"TRD_ae\"]\n",
    "test = test.reset_index()\n",
    "df_test = pd.concat([test,AE_predict], axis = 1)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(df_all[\"p\"], df_all[\"TPCROC1\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()\n",
    "plt.hist2d(df_test[\"p\"], df_test[\"TPCROC2_ae\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = train[[\"ITS_0\", \"TOF_0\", \"TPCROC0_0\", \"TPCROC1_0\", \"TPCROC2_0\", \"TRD_0\"]]\n",
    "test_0 = test[[\"ITS_0\", \"TOF_0\", \"TPCROC0_0\", \"TPCROC1_0\", \"TPCROC2_0\", \"TRD_0\"]]\n",
    "scaler_0 = StandardScaler()\n",
    "scaler_0.fit( train[[\"ITS_0\", \"TOF_0\", \"TPCROC0_0\", \"TPCROC1_0\", \"TPCROC2_0\", \"TRD_0\"]])\n",
    "#scaler_0.fit( train[[\"ITS\", \"TOF\", \"TPCROC0\", \"TPCROC1\", \"TPCROC2\", \"TRD\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"ITS_0\", \"TOF_0\", \"TPCROC0_0\", \"TPCROC1_0\", \"TPCROC2_0\", \"TRD_0\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"ITS\", \"TOF\", \"TPCROC0\", \"TPCROC1\", \"TPCROC2\", \"TRD\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.fit(scaler_0.transform(train_0), scaler_0.transform(train_0), epochs=5, batch_size=32, \n",
    "          validation_data=[scaler_0.transform(test_0),scaler_0.transform(test_0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = scaler_0.inverse_transform(model0.predict(scaler_0.transform(test_0)))\n",
    "AE_predict = pd.DataFrame(out)\n",
    "AE_predict.columns = [\"ITS_ae\", \"TOF_ae\", \"TPCROC0_ae\", \"TPCROC1_ae\", \"TPCROC2_ae\", \"TRD_ae\"]\n",
    "test = test.reset_index()\n",
    "df_test = pd.concat([test,AE_predict], axis = 1)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(df_all[\"p\"], df_all[\"TPCROC1\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()\n",
    "plt.hist2d(df_test[\"p\"], df_test[\"TPCROC2_ae\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labels for missing tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = train[[\"ITS_mr\", \"TOF_mr\", \"TPCROC0_mr\", \"TPCROC1_mr\", \"TPCROC2_mr\", \"TRD_mr\"]]\n",
    "train_out = train[[\"ITS\", \"TOF\", \"TPCROC0\", \"TPCROC1\", \"TPCROC2\", \"TRD\"]]\n",
    "test_in = test[[\"ITS_mr\", \"TOF_mr\", \"TPCROC0_mr\", \"TPCROC1_mr\", \"TPCROC2_mr\", \"TRD_mr\"]]\n",
    "test_out = test[[\"ITS\", \"TOF\", \"TPCROC0\", \"TPCROC1\", \"TPCROC2\", \"TRD\"]]\n",
    "scaler_in = StandardScaler()\n",
    "scaler_out = StandardScaler()\n",
    "scaler_in.fit(train_in)\n",
    "scaler_out.fit(train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell.fit(scaler_in.transform(train_in), scaler_out.transform(train_out), epochs=5, batch_size=32, \n",
    "          validation_data=[scaler_in.transform(test_in),scaler_out.transform(test_out)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = scaler_out.inverse_transform(modell.predict(scaler_in.transform(test_in)))\n",
    "AE_predict = pd.DataFrame(out)\n",
    "AE_predict.columns = [\"ITS_ae\", \"TOF_ae\", \"TPCROC0_ae\", \"TPCROC1_ae\", \"TPCROC2_ae\", \"TRD_ae\"]\n",
    "#test = test.reset_index()\n",
    "df_test = pd.concat([test,AE_predict], axis = 1)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(df_all[\"p\"], df_all[\"TPCROC1\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()\n",
    "plt.hist2d(df_test[\"p\"], df_test[\"TPCROC1_ae\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean input, zero weights for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mr = train[[\"ITS_mr\", \"TOF_mr\", \"TPCROC0_mr\", \"TPCROC1_mr\", \"TPCROC2_mr\", \"TRD_mr\"]]\n",
    "test_mr = test[[\"ITS_mr\", \"TOF_mr\", \"TPCROC0_mr\", \"TPCROC1_mr\", \"TPCROC2_mr\", \"TRD_mr\"]]\n",
    "train_w    = train[[\"ITS_w\", \"TOF_w\", \"TPCROC0_w\", \"TPCROC1_w\", \"TPCROC2_w\", \"TRD_w\"]]\n",
    "test_w     = test[[\"ITS_w\", \"TOF_w\", \"TPCROC0_w\", \"TPCROC1_w\", \"TPCROC2_w\", \"TRD_w\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_mr = StandardScaler()\n",
    "scaler_mr.fit(train_mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit([scaler_mr.transform(train_mr),train_w], scaler_mr.transform(train_mr), epochs=5, batch_size=32, \n",
    "          validation_data=[[scaler_mr.transform(test_mr),train_w],scaler_mr.transform(test_mr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = scaler_mr.inverse_transform(model1.predict([scaler_mr.transform(test_mr),test_w]))\n",
    "AE_predict = pd.DataFrame(out)\n",
    "AE_predict.columns = [\"ITS_ae\", \"TOF_ae\", \"TPCROC0_ae\", \"TPCROC1_ae\", \"TPCROC2_ae\", \"TRD_ae\"]\n",
    "#test = test.reset_index()\n",
    "df_test = pd.concat([test,AE_predict], axis = 1)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(df_all[\"p\"], df_all[\"TPCROC1\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()\n",
    "plt.hist2d(df_test[\"p\"], df_test[\"TPCROC1_ae\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second iteration, replace missing values by values from first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage 2\n",
    "stage2_data = df_stage_2[[\"ITS_mr\", \"TOF_mr\", \"TPCROC0_mr\", \"TPCROC1_mr\", \"TPCROC2_mr\", \"TRD_mr\"]]\n",
    "out = scaler_mr.inverse_transform(models2.predict(scaler_mr.transform(stage2_data)))\n",
    "AE_predict = pd.DataFrame(out)\n",
    "AE_predict.columns = [\"ITS_ae\", \"TOF_ae\", \"TPCROC0_ae\", \"TPCROC1_ae\", \"TPCROC2_ae\", \"TRD_ae\"]\n",
    "for i ,name in enumerate(['ITS','TOF','TPCROC0','TPCROC1','TPCROC2','TRD']):\n",
    "    # calculate \"flip= 0/1\"\n",
    "    f=(np.array(df_stage_2['flips'])>>i)&1\n",
    "    m=AE_predict[name+'_ae']\n",
    "    df_stage_2.loc[:,name+'_s2']= df_stage_2[name].multiply(f,axis='index')+m*(1-f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test =train_test_split(df_stage_2, test_size=0.5)\n",
    "train_s2 = train[[\"ITS_s2\", \"TOF_s2\", \"TPCROC0_s2\", \"TPCROC1_s2\", \"TPCROC2_s2\", \"TRD_s2\"]]\n",
    "test_s2 = test[[\"ITS_s2\", \"TOF_s2\", \"TPCROC0_s2\", \"TPCROC1_s2\", \"TPCROC2_s2\", \"TRD_s2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_s2 = StandardScaler()\n",
    "scaler_s2.fit(train_s2)\n",
    "models2.fit(scaler_s2.transform(train_s2), scaler_s2.transform(train_s2), epochs=5, batch_size=32, \n",
    "          validation_data=[scaler_s2.transform(test_s2),scaler_s2.transform(test_s2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = scaler_s2.inverse_transform(models2.predict(scaler_s2.transform(test_s2)))\n",
    "AE_predict = pd.DataFrame(out)\n",
    "AE_predict.columns = [\"ITS_ae\", \"TOF_ae\", \"TPCROC0_ae\", \"TPCROC1_ae\", \"TPCROC2_ae\", \"TRD_ae\"]\n",
    "test = test.reset_index()\n",
    "df_test = pd.concat([test,AE_predict], axis = 1)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(df_all[\"p\"], df_all[\"TPCROC1\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()\n",
    "plt.hist2d(df_test[\"p\"], df_test[\"TPCROC1_ae\"], bins=(100, 100), cmap=plt.cm.jet, range = [[0.2, 2], [0.5, 3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
