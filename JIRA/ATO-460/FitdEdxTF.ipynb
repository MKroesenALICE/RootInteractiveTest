{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from autoencoder import ToyDetectors, DEDXEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from __future__ import absolute_import ,division ,print_function\n",
    "from scipy.optimize import curve_fit\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfe = tf.contrib.eager\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD = ToyDetectors()\n",
    "DFTD = TD.GenerateToyParticles().sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFTD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = DFTD.query(\"particle!=1\")[[\"TPCROC0\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = DFTD.query(\"particle!=1\")[[\"p\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signalnp = np.array(signal)\n",
    "pnp = np.array(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(signalnp, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pnp, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BetheBlochAleph(bg,kp1,kp2,kp3,kp4,kp5):# ,kp1=0.76176e-1,kp2=10.632,kp3=0.13279e-4,kp4=1.8631,kp5=1.9479):\n",
    "            beta = bg/tf.sqrt(1.+ bg*bg)\n",
    "            aa   = tf.exp(kp4*tf.log(beta))\n",
    "            bb   = tf.exp(-kp5*tf.log(bg))\n",
    "            bb   = tf.log(kp3+bb)\n",
    "            return (kp2-aa-bb)*kp1/aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_e = 0.000511\n",
    "mass_pi = 0.139    \n",
    "mass_K = 0.494\n",
    "mass_p = 0.938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BetheBlochAlephNP(bg,kp1=0.76176e-1,kp2=10.632,kp3=0.13279e-4,kp4=1.8631,kp5=1.9479):\n",
    "        beta = bg/np.sqrt(1.+ bg*bg)\n",
    "        aa   = np.exp(kp4*np.log(beta))\n",
    "        bb   = np.exp(-kp5*np.log(bg))\n",
    "        bb   = np.log(kp3+bb)\n",
    "        return (kp2-aa-bb)*kp1/aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pnp\n",
    "y = signalnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0.1, 10., 0.1)\n",
    "plt.plot(t, BetheBlochAlephNP(t/mass_pi),t , BetheBlochAlephNP(t/mass_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(x, y, kp1, kp2, kp3, kp4, kp5): \n",
    "    pi_mean = BetheBlochAleph(x/mass_pi,kp1,kp2,kp3,kp4,kp5)\n",
    "    e_mean = BetheBlochAleph(x/mass_e,kp1,kp2,kp3,kp4,kp5) \n",
    "    p_mean = BetheBlochAleph(x/mass_p,kp1,kp2,kp3,kp4,kp5) \n",
    "    K_mean = BetheBlochAleph(x/mass_K,kp1,kp2,kp3,kp4,kp5)\n",
    "    \n",
    "    pi_sigma=0.1*pi_mean\n",
    "    e_sigma =0.1*e_mean\n",
    "    p_sigma =0.1*p_mean\n",
    "    K_sigma =0.1*K_mean\n",
    "    \n",
    "    p_pi    = tfd.Normal(loc=pi_mean,scale=pi_sigma).prob(y)\n",
    "    p_e     = tfd.Normal(loc= e_mean,scale= e_sigma).prob(y)\n",
    "    p_p     = tfd.Normal(loc= p_mean,scale= p_sigma).prob(y)\n",
    "    p_K     = tfd.Normal(loc= K_mean,scale= K_sigma).prob(y)\n",
    "    \n",
    "    \n",
    "    lnp = tf.log((p_pi   + p_e + p_p + p_K)/4.)\n",
    "    \n",
    "    extraloss = - 1e3*(kp3-0.13279e-4)**2\n",
    "    return tf.reduce_mean(lnp) + extraloss\n",
    "\n",
    "\n",
    "unnormalized_posterior_log_prob = lambda *args: log_prob(x,y, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1 = tf.Variable(0.7 ,dtype=tf.float64,name=\"kp1\") # 0.76176e-1\n",
    "kp2 = tf.Variable(12.0,dtype=tf.float64,name=\"kp2\") # 10.632\n",
    "kp3 = tf.Variable(0.13279e-4,dtype=tf.float64,name=\"kp3\")\n",
    "kp4 = tf.Variable(2.0,dtype=tf.float64,name=\"kp4\") # 1.8631\n",
    "kp5 = tf.Variable(2.2,dtype=tf.float64,name=\"kp5\") # 1.9479\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=-unnormalized_posterior_log_prob(kp1,kp2,tf.sqrt(kp3**2),kp4,kp5)\n",
    "optimizer=tf.train.AdagradOptimizer(learning_rate=0.01)\n",
    "trainer  =optimizer.minimize(loss,var_list=[kp1,kp2,kp3,kp4,kp5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init =tf.global_variables_initializer() \n",
    "#with tf.Session() as session:\n",
    "#    session.run(init)\n",
    "#    print(session.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init =tf.global_variables_initializer() \n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    for _ in range(5000):\n",
    "        l1=session.run(loss)\n",
    "        session.run(trainer)\n",
    "        l2=session.run(loss)\n",
    "        kp1_v=session.run(kp1)\n",
    "        kp2_v=session.run(kp2)\n",
    "        kp3_v=np.abs(session.run(kp3))\n",
    "        kp4_v=session.run(kp4)\n",
    "        kp5_v=session.run(kp5)\n",
    "        \n",
    "        \n",
    "        print(\"loss (prev): \",l1,\"loss (post): \",l2)\n",
    "        print(kp1_v,kp2_v,kp3_v,kp4_v,kp5_v)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame([kp1_v, kp2_v, kp3_v, kp4_v, kp5_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.transpose().to_csv(\"MCMCresults.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
